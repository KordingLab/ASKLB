{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASKLB Jupyter Notebook \n",
    "### Note: If running on new Google Colab instance, run the three lines below to download dependencies:\n",
    "!apt-get install build-essential swig <br>\n",
    "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install <br>\n",
    "!pip install auto-sklearn\n",
    "\n",
    "### Colab Link\n",
    "https://colab.research.google.com/github/KordingLab/ASKLB/blob/master/notebooks/ASKLB_Notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f3b74a449f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import numpy\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox, Label\n",
    "import warnings\n",
    "import threading\n",
    "import time\n",
    "import os, sys\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load X and y datasets\n",
    "Should have names automl_X.csv and automl_Y.csv respectively (will see if I can use a file upload widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.loadtxt('automl_X.csv', delimiter=',')\n",
    "y = numpy.loadtxt('automl_y.csv', delimiter=',')\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "def work(progress):\n",
    "        for i in range(int(progress.max/5)):\n",
    "            time.sleep(5)\n",
    "            progress.value = progress.value+5\n",
    "\n",
    "def on_button_clicked(b):    \n",
    "    models_output.clear_output()\n",
    "    metrics_output.clear_output()\n",
    "    final_runtime_value_seconds = runtime_widget.value * 60\n",
    "    progress.value = 0    \n",
    "    progress.max=final_runtime_value_seconds\n",
    "    with output:\n",
    "        print(\"AUTOML FITTING STARTED, FITTING TIME IS \", int(final_runtime_value_seconds/60), \" MINUTES\")\n",
    "        \n",
    "    automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = final_runtime_value_seconds)        \n",
    "    thread = threading.Thread(target=work, args=(progress,))    \n",
    "    thread.start()\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        with HiddenPrints():\n",
    "            automl.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"FITTING COMPLETED\")\n",
    "        \n",
    "    with metrics_output:            \n",
    "        y_train_hat = automl.predict(X_train)\n",
    "        train_accuracy_score = sklearn.metrics.accuracy_score(y_train, y_train_hat)\n",
    "        print(\"Training Accuracy Score: \", train_accuracy_score)\n",
    "        \n",
    "        \n",
    "        y_test_hat = automl.predict(X_test)\n",
    "        test_accuracy_score = sklearn.metrics.accuracy_score(y_test, y_test_hat)\n",
    "        print(\"Testing Accuracy Score: \", test_accuracy_score)\n",
    "        \n",
    "        fpr_train, tpr_train, threshold_train = metrics.roc_curve(y_train, y_train_hat)\n",
    "        roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "        \n",
    "        print(\"Training ROC AUC: \", roc_auc_train)\n",
    "        \n",
    "        %matplotlib notebook        \n",
    "        plt.title('Train ROC')\n",
    "        plt.plot(fpr_train, tpr_train, 'b', label = 'AUC = %0.2f' % roc_auc_train)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()        \n",
    "        \n",
    "        fpr_test, tpr_test, threshold_test = metrics.roc_curve(y_test, y_test_hat)\n",
    "        roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "        \n",
    "        print(\"Test ROC AUC: \", roc_auc_test)\n",
    "        \n",
    "        %matplotlib notebook        \n",
    "        plt.title('Test ROC')\n",
    "        plt.plot(fpr_test, tpr_test, 'b', label = 'AUC = %0.2f' % roc_auc_test)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "        \n",
    "    with models_output:\n",
    "        print(\"MODELS:\")\n",
    "        print(automl.get_models_with_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_widget = widgets.IntSlider(\n",
    "    value=15,\n",
    "    min=1,\n",
    "    max=60)\n",
    "\n",
    "progress = widgets.IntProgress(value=0, min=0, description=\"Progress\")\n",
    "\n",
    "button = widgets.Button(description=\"Fit to AutoML\")\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "runtime_slider = HBox([Label('AutoML Runtime (minutes)'), runtime_widget])\n",
    "\n",
    "output = widgets.Output()\n",
    "metrics_output = widgets.Output()\n",
    "models_output = widgets.Output()\n",
    "models_accordian = widgets.Accordion(children=[metrics_output, models_output])\n",
    "models_accordian.set_title(0, 'Performance Metrics')\n",
    "models_accordian.set_title(1, 'Models and Weights Data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML WIDGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84692530155e4b099ec52bdece7fa5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='AutoML Runtime (minutes)'), IntSlider(value=15, max=60, min=1)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286b4f642de64eecbc35c1567f26a2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Fit to AutoML', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4ecbbdda3c4d8380434ce1ac511afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d2eed1f1cf405e9a913b7208ad3744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c521b35c7c42fd8e963fbdf1e02417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(), Output()), _titles={'0': 'Performance Metrics', '1': 'Models and Weights Data'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING COMPLETED\n"
     ]
    }
   ],
   "source": [
    "display(runtime_slider)\n",
    "display(button)\n",
    "display(progress)\n",
    "display(output)\n",
    "display(models_accordian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = 30)\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = automl.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = models[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = automl.predict(X_test)\n",
    "autosklearn.metrics.roc_auc(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.shape(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_hat)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:auto-sklearn]",
   "language": "python",
   "name": "conda-env-auto-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
